<!-- TOC start (generated with https://github.com/derlin/bitdowntoc) -->

   * [General Commands](#general-commands)
   * [Remote Connection to Instances](#remote-connection-to-instances)
      + [SSH into Linux](#ssh-into-linux)
      + [RDP into Windows](#rdp-into-windows)
   * [Compute Engine Instances](#compute-engine-instances)
   * [Firewall](#firewall)
   * [Cloud logging](#cloud-logging)
   * [VPC network](#vpc-network)
   * [IAM Roles commands](#iam-roles-commands)
   * [Service Accounts](#service-accounts)
   * [Routes](#routes)
   * [AppEngine](#appengine)
   * [KMS](#kms)
   * [Google Kubernetes engine (GKE)](#google-kubernetes-engine-gke)
   * [Gsutil](#gsutil)
   * [Organization policy](#organization-policy)
   * [Big Query](#big-query)
   * [**self-managed SSL certificate**](#self-managed-ssl-certificate)
   * [Secret Manager](#secret-manager)
   * [HA VPN](#ha-vpn)
   * [Load Balancer](#load-balancer)
   * [Google containers](#google-containers)
   * [Artifact Registry](#artifact-registry)
   * [Source Repos](#source-repos)
   * [Cloud Armor](#cloud-armor)

<!-- TOC end -->

<!-- TOC --><a name="gcloud-cli-commands"></a>
# GCloud CLI commands

<!-- TOC --><a name="general-commands"></a>
## General Commands

```bash
gcloud auth list  # active account name
gcloud config set account `ACCOUNT`  # to set active account
gcloud config list project  

# Region and zone shell commands
gcloud config set compute/region REGION
gcloud config get-value compute/region
gcloud config set compute/zone ZONE
gcloud config get-value compute/zone

# project information
gcloud config get-value project
gcloud compute project-info describe --project $(gcloud config get-value project)

# environment variables
export PROJECT_ID=$(gcloud config get-value project)
# same bash commands

# Creating a virtual machine with the gcloud tool
gcloud compute instances create gcelab2 --machine-type e2-medium --zone $ZONE
gcloud compute instances create --help

# help
gcloud -h 
# You can access more verbose help by appending the 
# --help flag onto a command or running the gcloud help command.
gcloud config --help
gcloud help config

gcloud config list
gcloud config list --all
gcloud components list

```

<!-- TOC --><a name="remote-connection-to-instances"></a>
## Remote Connection to Instances

<!-- TOC --><a name="ssh-into-linux"></a>
### SSH into Linux

```bash
# Connecting to your VM instance
gcloud compute ssh gcelab2 --zone $ZONE
--internal-ip # to use internal ip for connection VM to VM connection
--tunnel-through-iap # iap tunneling
```

<!-- TOC --><a name="rdp-into-windows"></a>
### RDP into Windows

1. To see whether the server instance is ready for an RDP connection, run the following command at your Cloud Shell terminal command line: `gcloud compute instances get-serial-port-output instance-1`
2. To set a password for logging into the RDP, run the following command in Cloud Shell. Be sure you replace `[instance]` with the VM Instance that you created, `[zone]` that you defined earlier and set `[username]` as **admin**.

```bash
gcloud compute reset-windows-password [instance] --zone [zone] --user [username]
```

```bash
# to create storage bucket in the project
gcloud storage buckets create -l us-central1 gs://$DEVSHELL_PROJECT_ID
gcloud storage cp sample.txt gs://$DEVSHELL_PROJECT_ID
gcloud storage ls gs://$DEVSHELL_PROJECT_ID
```

<!-- TOC --><a name="compute-engine-instances"></a>
## Compute Engine Instances

```bash
# instance creation and using startup script
gcloud compute instances create www1 \
    --zone=Zone \
    --tags=network-lb-tag \
    --machine-type=e2-small \
    --image-family=debian-11 \
    --image-project=debian-cloud \
    --metadata=startup-script='#!/bin/bash
      apt-get update
      apt-get install apache2 -y
      service apache2 restart
      echo "
<h3>Web Server: www1</h3>" | tee /var/www/html/index.html'

# instance creation using container image.
gcloud compute instances create-with-container owasp-juice-shop-app --container-image bkimminich/juice-shop \
     --network ca-lab-vpc \
     --subnet ca-lab-subnet \
     --private-network-ip=10.0.0.3 \
     --machine-type n1-standard-2 \
     --zone us-east4-b \
     --tags allow-healthcheck
     
# Unmanaged instance group creation
gcloud compute instance-groups unmanaged create juice-shop-group \
    --zone=us-east4-b

# add instance in the Unmanaged group
gcloud compute instance-groups unmanaged add-instances juice-shop-group \
    --zone=us-east4-b \
    --instances=owasp-juice-shop-app

# List Instances
gcloud compute instances list
gcloud compute instances list --filter="name=('gcelab2')"
```

<!-- TOC --><a name="firewall"></a>
## Firewall

```bash
# create firewall rule
gcloud compute firewall-rules create www-firewall-network-lb \
    --target-tags network-lb-tag --allow tcp:80

gcloud compute firewall-rules create default-allow-http --direction=INGRESS \
--priority=1000 --network=default --action=ALLOW --rules=tcp:80 \
--source-ranges=0.0.0.0/0 --target-tags=http-server

gcloud compute firewall-rules list
gcloud compute firewall-rules list --filter="network='default'"
gcloud compute firewall-rules list --filter="NETWORK:'default' AND ALLOW:'icmp'"

# Updating and creating the firewall
gcloud compute instances add-tags gcelab2 --tags http-server,https-server

gcloud compute firewall-rules list --filter=ALLOW:'80'

# communicating web server for firewall testing
curl http://$(gcloud compute instances list --filter=name:gcelab2 --format='value(EXTERNAL_IP)')
```

<!-- TOC --><a name="cloud-logging"></a>
## Cloud logging

```bash
gcloud logging logs list
gcloud logging logs list --filter="compute"
gcloud logging read "resource.type=gce_instance" --limit 5
gcloud logging read "resource.type=gce_instance AND labels.instance_name='gcelab2'" --limit 
```

**Note:** Cloud Logging exports incoming log entries before any decision is made about ingesting the entry into logging storage. As a result, only new log entries will be exported to the sink. As a result, you may not see a `syslog_(1)` table as all the syslog entries were generated prior to the export.

Existing log entries already ingested into Cloud Logging can be extracted using commands like:

```
gcloud logging read "resource.type=gce_instance AND logName=projects/[PROJECT_ID]/logs/syslog AND textPayload:SyncAddress" --limit 10 --format json
```

<!-- TOC --><a name="vpc-network"></a>
## VPC network

```bash
# auto mode vpc network
gcloud compute networks create mynetwork --subnet-mode=auto
# this will automatically creates subnet ip range in each region

# custom mode vpc network
gcloud compute networks create privatenet \
--subnet-mode=custom

gcloud compute networks subnets create privatesubnet \
--network=privatenet --region=us-central1 \
--range=10.0.0.0/24 --enable-private-ip-google-access

# to create allow rule in firewall from specific ip
ip=$(curl -s https://api.ipify.org)
echo "My External IP address is: $ip"

gcloud compute firewall-rules create \
mynetwork-ingress-allow-ssh-from-cs \
--network mynetwork --action ALLOW --direction INGRESS \
--rules tcp:22 --source-ranges $ip --target-tags=lab-ssh

# to enable global routing within the VPC network for routers, by default it's regional
gcloud compute networks update vpc-demo --bgp-routing-mode GLOBAL

# enable flow logging
gcloud compute networks subnets update default \
--region us-central1 --enable-flow-logs \
--logging-metadata=include-all

# to disable
gcloud compute networks subnets update default \
--region europe-west1 --no-enable-flow-logs
```

<!-- TOC --><a name="iam-roles-commands"></a>
## IAM Roles commands

```bash
# list of available permisions that can be applied to the role
gcloud iam list-testable-permissions //cloudresourcemanager.googleapis.com/projects/$DEVSHELL_PROJECT_ID

# roles metadata
gcloud iam roles describe [ROLE_NAME]

#  list of all roles that can be applied to a given resource.
gcloud iam list-grantable-roles //cloudresourcemanager.googleapis.com/projects/$DEVSHELL_PROJECT_ID

# service accounts iam policy
gcloud iam service-accounts get-iam-policy <SERVICE_ACCOUNT_NAME>
```

```yaml
# role.yaml
title: App Viewer
description: Custom role to view apps
stage: ALPHA
includedPermissions:
- compute.instances.get
- compute.instances.list
- appengine.versions.get
- appengine.versions.list
```

```bash
# to create custom role using yaml file
gcloud iam roles create app_viewer --project \
$DEVSHELL_PROJECT_ID --file role.yaml

# using flags given to command
gcloud iam roles create viewer --project $DEVSHELL_PROJECT_ID \
--title "Role Viewer" --description "Custom role description." \
--permissions compute.instances.get,compute.instances.list --stage ALPHA

# to list all the custom roles
gcloud iam roles list --project $DEVSHELL_PROJECT_ID
# to list predefined roles
gcloud iam roles list

# to get the role's definition
gcloud iam roles describe app_viewer --project \
$DEVSHELL_PROJECT_ID

# after getting yaml file with etag from above command 
# update perms and use the below 
gcloud iam roles update app_viewer --project \
$DEVSHELL_PROJECT_ID --file update-role.yaml

# update through flags
gcloud iam roles update viewer --project $DEVSHELL_PROJECT_ID \
--add-permissions storage.buckets.get,storage.buckets.list

# to disable the role
gcloud iam roles update app_viewer --project \
$DEVSHELL_PROJECT_ID --stage DISABLED

# to delete, within 7 days after deletion, undeletion can be done
gcloud iam roles delete app_viewer --project \
$DEVSHELL_PROJECT_ID

# to show the deleted roles too
gcloud iam roles list --project $DEVSHELL_PROJECT_ID \
--show-deleted

# to undelete the role
gcloud iam roles undelete app_viewer --project \
$DEVSHELL_PROJECT_ID
```

<!-- TOC --><a name="service-accounts"></a>
## Service Accounts

```bash
# create service account
gcloud iam service-accounts create my-sa-123 --display-name "my service account"

# Roles assignment to service account
gcloud projects add-iam-policy-binding $DEVSHELL_PROJECT_ID \
    --member serviceAccount:my-sa-123@$DEVSHELL_PROJECT_ID.iam.gserviceaccount.com --role roles/editor

# upload pub key to service account
gcloud iam service-accounts keys upload PUB_KEY_FILE --iam-account=SERVICE_ACCOUNT

# create key pair to service account
gcloud iam service-accounts keys create OUTPUT_HAVING_PRIV_KEY --iam-account=SERVICE_ACCOUNT

# list keys
gcloud iam service-accounts keys list --iam-account=SERVICE_ACCOUNT

# Delete key
gcloud iam service-accounts keys delete KEY_ID --iam-account=SERVICE_ACCOUNT

```

<!-- TOC --><a name="routes"></a>
## Routes

```bash
gcloud compute routes list --project 
```

<!-- TOC --><a name="appengine"></a>
## AppEngine

```bash
gcloud app create --project=$(gcloud config get-value project) --region=us-east1

# execute in the folder of source code or program
gcloud app deploy

# yaml file example
runtime: python37
automatic_scaling:
  max_instances: 2
  
  
gcloud app browse

gcloud services disable appengineflex.googleapis.com
```

**Note:** App Engine has its standard and flexible environments which are optimized for different application architectures. Currently, when enabling IAP for App Engine, if the Flex API is enabled, Google Cloud will look for a Flex Service Account. Your lab project comes with a multitude of APIs already enabled for the purpose of convenience. However, this creates a unique situation where the Flex API is enabled without a Service Account created.

<!-- TOC --><a name="kms"></a>
## KMS

```bash
gcloud services enable cloudkms.googleapis.com

gcloud kms keyrings create $KEYRING_NAME --location global

gcloud kms keys create $CRYPTOKEY_NAME --location global \
      --keyring $KEYRING_NAME \
      --purpose encryption
      
# for every encryption it uses different versions of keys, 
# same data results in different ciphers
# data encryption
PLAINTEXT=$(cat 1. | base64 -w0)
curl -v "https://cloudkms.googleapis.com/v1/projects/$DEVSHELL_PROJECT_ID/locations/global/keyRings/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_NAME:encrypt" \
  -d "{\"plaintext\":\"$PLAINTEXT\"}" \
  -H "Authorization:Bearer $(gcloud auth application-default print-access-token)"\
  -H "Content-Type: application/json" \
  | jq .ciphertext -r > 1.encrypted
  
# using gcloud
gcloud kms encrypt \
    --location "global" \
    --keyring "test" \
    --key "quickstart" \
    --plaintext-file ./mysecret.txt \
    --ciphertext-file ./mysecret.txt.encrypted
  
# data decryption, checks the version from the cipher
curl -v "https://cloudkms.googleapis.com/v1/projects/$DEVSHELL_PROJECT_ID/locations/global/keyRings/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_NAME:decrypt" \
  -d "{\"ciphertext\":\"$(cat 1.encrypted)\"}" \
  -H "Authorization:Bearer $(gcloud auth application-default print-access-token)"\
  -H "Content-Type:application/json" \
| jq .plaintext -r | base64 -d

# curl send response in base64 encoded whereas gcloud kms doesn't

# list all the versions related to our key
gcloud kms keys versions list \
    --location "global" \
    --keyring "test" \
    --key "quickstart"

gcloud kms keys versions destroy key-version \
    --location "global" \
    --keyring "test" \
    --key "quickstart"
    
# assign iam permissions to user related to kms management
gcloud kms keyrings add-iam-policy-binding $KEYRING_NAME \
    --location global \
    --member user:$USER_EMAIL \
    --role roles/cloudkms.admin

# for enabling the user to use keys
    --role roles/cloudkms.cryptoKeyEncrypterDecrypter
 
# To give your Cloud Storage service account permission 
# to use both of your Cloud KMS keys:
gsutil kms authorize -p $DEVSHELL_PROJECT_ID -k \
projects/$DEVSHELL_PROJECT_ID/locations/us/keyRings\
/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_1_NAME
gsutil kms authorize -p $DEVSHELL_PROJECT_ID -k \
projects/$DEVSHELL_PROJECT_ID/locations/us/keyRings\
/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_2_NAME

# To set the default key for your bucket to the first key you generated:
gsutil kms encryption -k \
projects/$DEVSHELL_PROJECT_ID/locations/us/keyRings\
/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_1_NAME \
gs://$DEVSHELL_PROJECT_ID-kms

# to check the default key used by storage service acount
gsutil kms encryption gs://[bucket_name]

# encrypting individual object using selected encryption key
gsutil -o \
"GSUtil:encryption_key=projects/$DEVSHELL_PROJECT_ID/locations/us/keyRings\
/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_2_NAME" \
cp file3.txt gs://$DEVSHELL_PROJECT_ID-kms
```

<!-- TOC --><a name="google-kubernetes-engine-gke"></a>
## Google Kubernetes engine (GKE)

```yaml
# create private kubernetes cluster
gcloud beta container clusters create private-cluster \
    --enable-private-nodes \
    --master-ipv4-cidr 172.16.0.16/28 \
    --enable-ip-alias \
    --create-subnetwork ""
    
# Find the automatically created subnet for kubernetes pods
# name might look like gke-private-cluster-subnet-xxxxxxxx
gcloud compute networks subnets list --network <Network>

# Create a source instance which you'll use to check the 
# connectivity to Kubernetes clusters:
gcloud compute instances create source-instance \
 --zone=$ZONE --scopes 'https://www.googleapis.com/auth/cloud-platform'

# authorize your vm to master <yourip>/32
gcloud container clusters update private-cluster \
    --enable-master-authorized-networks \
    --master-authorized-networks [MY_EXTERNAL_RANGE]
    
# installation in master authorized network VM
sudo apt-get install kubectl
sudo apt-get install google-cloud-sdk-gke-gcloud-auth-plugin
gcloud container clusters get-credentials private-cluster --zone=$ZONE

# to verify that our nodes don't have external IP
kubectl get nodes --output yaml | grep -A4 addresses

# to delete k8s cluster
gcloud container clusters delete private-cluster --zone=$ZONE 

# you can create your own custom subnet for private k8s cluster
gcloud compute networks subnets create my-subnet \
    --network default \
    --range 10.0.4.0/22 \
    --enable-private-ip-google-access \
    --region=$REGION \
    --secondary-range my-svc-range=10.0.32.0/20,my-pod-range=10.4.0.0/14
# private k8s cluster with custom subnet
gcloud beta container clusters create private-cluster2 \
    --enable-private-nodes \
    --enable-ip-alias \
    --master-ipv4-cidr 172.16.0.32/28 \
    --subnetwork my-subnet \
    --services-secondary-range-name my-svc-range \
    --cluster-secondary-range-name my-pod-range \
    --zone=$ZONE
    
# to check about container watcher used by container threat detection
kubectl describe daemonsets container-watcher -n kube-system
```

```bash
gcloud container clusters create gmp-cluster --num-nodes=1 --zone us-east1-c

gcloud container clusters list

# Authenticate the cluster
gcloud container clusters get-credentials gmp-cluster

# Create a namespace to work in
kubectl create ns gmp-test

# to deploy a simple application that emits metrics at the /metrics endpoint:
kubectl -n gmp-test apply \
-f https://storage.googleapis.com/spls/gsp091/gmp_flask_deployment.yaml

kubectl -n gmp-test apply \
-f https://storage.googleapis.com/spls/gsp091/gmp_flask_service.yaml

# verify the namespace is ready and emitting metrics
kubectl get services -n gmp-test
```

<!-- TOC --><a name="gsutil"></a>
## Gsutil

```bash
 # to create bucket
 gsutil mb gs://[bucketname]
 
 # set permission for public use, if access control on bucket is fine grained
 gsutil acl ch -u AllUsers:R gs://[your-storage-bucket]/cdn.png
 
 # to check default encryption key on the bucket
 gsutil kms encryption gs://[bucket_name]
 # The bucket should not currently have a default encryption key. 
 # This means all data in the bucket will be encrypted by Google-managed encryption keys.
 
 
 # encrypting individual object using selected encryption key
 gsutil -o \
"GSUtil:encryption_key=projects/$DEVSHELL_PROJECT_ID/locations/us/keyRings\
/$KEYRING_NAME/cryptoKeys/$CRYPTOKEY_2_NAME" \
cp file3.txt gs://$DEVSHELL_PROJECT_ID-kms

# to list all the file details
gsutil ls -L gs://$DEVSHELL_PROJECT_ID-kms/file3.txt

# signed url creation
gsutil signurl -d 10m <private-key-file> gs://<bucket>/<object>
# max duration allowed 7 days for priv key
# max 12 hrs when -u, Use service account credentials 

gcloud storage sign-url gs://super-secure-bucket/noir.jpg \
--private-key-fi1e=4key.json —duration-10m
```

<!-- TOC --><a name="organization-policy"></a>
## Organization policy

```bash
# get existing policy settings
gcloud resource-manager org-policies describe \
compute.trustedImageProjects --project=$DEVSHELL_PROJECT_ID --effective > policy.yaml

# open the policy yaml and made changes according to your needs

# apply the org policy
gcloud resource-manager org-policies set-policy policy.yaml \
--project=$DEVSHELL_PROJECT_ID 
```

<!-- TOC --><a name="big-query"></a>
## Big Query

```bash
# to load the dataset table with the data
bq load --autodetect $DEVSHELL_PROJ:dataset_name.table_name \
gs://cloud-training/gcpsec/labs/bq-authviews-source.csv
```

<!-- TOC --><a name="self-managed-ssl-certificate"></a>
## **self-managed SSL certificate**

```bash
# To create a new private key with RSA-2048 encryption 
# in the PEM format OpenSSL
openssl genrsa -out PRIVATE_KEY_FILE 2048

# To create a certificate signing request (CSR) file
openssl req -new -key PRIVATE_KEY_FILE \
 -out CSR_FILE \
 -config ssl_config
 
 # To create a self-signed certificate for testing
openssl x509 -req \
 -signkey PRIVATE_KEY_FILE \
 -in CSR_FILE \
 -out CERTIFICATE_FILE.pem \
 -extfile ssl_config \
 -extensions extension_requirements \
 -days 365
 
 # To create a global SSL certificate, 
 # use the gcloud compute ssl-certificates create command with the --global flag
 gcloud compute ssl-certificates create my-cert \
 --certificate=CERTIFICATE_FILE.pem \
 --private-key=PRIVATE_KEY_FILE \
 --global
```

<!-- TOC --><a name="secret-manager"></a>
## Secret Manager

```bash
# To create secret in secret manager, 
# printf or echo -n used to avoid entering newline character
printf "value1"  | gcloud secrets create KEY_NAME --data-file=- --labels=team=acme
# to add the new version
printf 'value2' | gcloud secrets versions add KEY_NAME --data-file=-

# to access the secret where 1 is version number
# use 'latest' in place of 1 for latest version
gcloud secrets versions access 1 --secret="KEY_NAME"
```

<!-- TOC --><a name="ha-vpn"></a>
## HA VPN

```bash
# VPN gateway creation
gcloud compute vpn-gateways create vpc-demo-vpn-gw1 \
--network vpc-demo --region us-central1

# after that create cloud router on that same network
gcloud compute routers create vpc-demo-router1 \
    --region us-central1 \
    --network vpc-demo \
    --asn 65001
    
# you can create VPN gateway and cloud router (asn + 1) in 2 different VPC net
# create VPN tunnel
gcloud compute vpn-tunnels create vpc-demo-tunnel0 \
    --peer-gcp-gateway on-prem-vpn-gw1 \
    --region us-central1 \
    --ike-version 2 \
    --shared-secret [SHARED_SECRET] \
    --router vpc-demo-router1 \
    --vpn-gateway vpc-demo-vpn-gw1 \
    --interface 0
# create vpn tunnel from both side of the network and each interface

#  configure BGP peering for each VPN tunnel between vpc-demo and VPC on-prem. 
# HA VPN requires dynamic routing to enable 99.99% availability.
gcloud compute routers add-interface vpc-demo-router1 \
    --interface-name if-tunnel0-to-on-prem \
    --ip-address 169.254.0.1 \
    --mask-length 30 \
    --vpn-tunnel vpc-demo-tunnel0 \
    --region us-central1
    
gcloud compute routers add-bgp-peer vpc-demo-router1 \
    --peer-name bgp-on-prem-tunnel0 \
    --interface if-tunnel0-to-on-prem \
    --peer-ip-address 169.254.0.2 \
    --peer-asn 65002 \
    --region us-central1

# run the above two commands for interface 1 of vpn gateway as well and also 
# same setup for another vpc net

gcloud compute vpn-tunnels list
gcloud compute vpn-tunnels describe vpc-demo-tunnel0 \
      --region us-central1
    
# to delete tunnels
gcloud compute vpn-tunnels delete vpc-demo-tunnel1  --region us-central1
# to remove bgp peering
gcloud compute routers remove-bgp-peer vpc-demo-router1 \
--peer-name bgp-on-prem-tunnel0 --region us-central1
# to delete cloud routers
gcloud compute  routers delete on-prem-router1 --region us-central1
# to delete vpn gateways
gcloud compute vpn-gateways delete vpc-demo-vpn-gw1 --region us-central1
```

<!-- TOC --><a name="load-balancer"></a>
## Load Balancer

```bash
# to get the health status of backend service of load balancer
gcloud compute backend-services get-health web-backend --global

# to get forwarding rules of load balancer and external ip
gcloud compute forwarding-rules describe web-rule --global

# health check creation
gcloud compute health-checks create tcp tcp-port-3000 \
        --port 3000

# backend service creation
gcloud compute backend-services create juice-shop-backend \
        --protocol HTTP \
        --port-name http \
        --health-checks tcp-port-3000 \
        --enable-logging \
        --global
      
# add backend in backend service
 gcloud compute backend-services add-backend juice-shop-backend \
        --instance-group=juice-shop-group \
        --instance-group-zone=us-east4-b \
        --global  
    
# url map create
gcloud compute url-maps create juice-shop-loadbalancer \
        --default-service juice-shop-backend
        
# target proxy setup
gcloud compute target-http-proxies create juice-shop-proxy \
        --url-map juice-shop-loadbalancer
        
# forwarding rule
gcloud compute forwarding-rules create juice-shop-rule \
        --global \
        --target-http-proxy=juice-shop-proxy \
        --ports=80
```

<!-- TOC --><a name="google-containers"></a>
## Google containers

```bash
gcloud container images list

gcloud container images list --repository gcr.io/google-containers

gcloud container images list-tags "gcr.io/${PROJECT_ID}/nginx"
```

<!-- TOC --><a name="artifact-registry"></a>
## Artifact Registry

```bash
gcloud artifacts repositories create container-dev-repo --repository-format=docker \
  --location=$REGION \
  --description="Docker repository for Container Dev Workshop"
```

<!-- TOC --><a name="source-repos"></a>
## Source Repos

```bash
gcloud source repos clone hello-cloudbuild-env

gcloud source repos create hello-cloudbuild-app

```

<!-- TOC --><a name="cloud-armor"></a>
## Cloud Armor

```bash
# preconfigured WAF rules
gcloud compute security-policies list-preconfigured-expression-sets

# policy creation
gcloud compute security-policies create block-with-modsec-crs \
    --description "Block with OWASP ModSecurity CRS"

# rule update
gcloud compute security-policies rules update 2147483647 \
    --security-policy block-with-modsec-crs \
    --action "deny-403"
    
# rule creation
gcloud compute security-policies rules create 10000 \
    --security-policy block-with-modsec-crs  \
    --description "allow traffic from my IP" \
    --src-ip-ranges "$MY_IP/32" \
    --action "allow"

# path traversal security policy
gcloud compute security-policies rules create 9000 \
    --security-policy block-with-modsec-crs  \
    --description "block local file inclusion" \
     --expression "evaluatePreconfiguredExpr('lfi-stable')" \
    --action deny-403

# RCE
gcloud compute security-policies rules create 9001 \
    --security-policy block-with-modsec-crs  \
    --description "block rce attacks" \
     --expression "evaluatePreconfiguredExpr('rce-stable')" \
    --action deny-403

# Scanner detection
gcloud compute security-policies rules create 9002 \
    --security-policy block-with-modsec-crs  \
    --description "block scanners" \
     --expression "evaluatePreconfiguredExpr('scannerdetection-stable')" \
    --action deny-403

# OWASP ModSecurity Core Rule Set, apply rules that look 
# for Carriage Return (CR) %0d and Linefeed (LF)%0a characters and 
# other types of protocol attacks like HTTP Request Smuggling.
gcloud compute security-policies rules create 9003 \
    --security-policy block-with-modsec-crs  \
    --description "block protocol attacks" \
     --expression "evaluatePreconfiguredExpr('protocolattack-stable')" \
    --action deny-403
 
# security policy to block session fixation
gcloud compute security-policies rules create 9004 \
    --security-policy block-with-modsec-crs \
    --description "block session fixation attacks" \
     --expression "evaluatePreconfiguredExpr('sessionfixation-stable')" \
    --action deny-403

# attach security policy to backend services
gcloud compute backend-services update juice-shop-backend \
    --security-policy block-with-modsec-crs \
    --global
```